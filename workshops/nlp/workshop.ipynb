{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</figure>\n",
    "<center> <h1>OpenVINO™ Deep Learning Workbench: NLP TITLE</h1> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. [Introduction](#intro)\n",
    "\n",
    "## 2. [OpenVINO™ Overview](#OV-overview)\n",
    "\n",
    "## 3. [OpenVINO™ Deep Learning Workbench](#DL-WB-overview)\n",
    "\n",
    "## 4. [OpenVINO™ API](#OV-API)\n",
    "\n",
    "## 5. [Practice](#tasks)\n",
    "\n",
    "## 6. [Bonus: Deploy your first OpenVINO application as a telegram bot](#bot)\n",
    "\n",
    "## 7. [Bonus: Next steps with OpenVINO](#next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction  <a name=\"intro\"></a>\n",
    "\n",
    "### Workshop Contributors\n",
    "\n",
    "<div style=\"display: block; text-align: center;\">\n",
    "    <figure style=\"display: inline-block;\">\n",
    "      <img style=\"border-radius: 50%;\" src=\"pictures/Demidovskij.jpg\" width=\"150\" height=\"150\"/>\n",
    "      <figcaption style=\"text-align: center; font-weight: bold;\">Alexander Demidovskij</figcaption>\n",
    "      <figcaption style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/demid5111\" style=\"display: inline-flex;\"><img src=\"./pictures/github.svg\" width=\"22px\" style=\"margin-right: 5px\">@demid5111</a>\n",
    "      </figcaption>\n",
    "    </figure>\n",
    "    <figure style=\"display: inline-block;\">\n",
    "      <img style=\"border-radius: 50%;\" src=\"pictures/\" width=\"150\" height=\"150\"/>\n",
    "      <figcaption style=\"text-align: center; font-weight: bold;\">Artur Paniukov</figcaption>\n",
    "      <figcaption style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/apaniukov\" style=\"display: inline-flex;\"><img src=\"./pictures/github.svg\" width=\"22px\" style=\"margin-right: 5px\">@apaniukov</a>\n",
    "      </figcaption>\n",
    "    </figure>\n",
    "    <br>\n",
    "      <figure style=\"display: inline-block;\">\n",
    "      <img style=\"border-radius: 50%;\" src=\"pictures/Tugaryov.jpg\" width=\"150\" height=\"150\"/>\n",
    "      <figcaption style=\"text-align: center; font-weight: bold;\">Artyom Tugaryov</figcaption>\n",
    "      <figcaption style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/artyomtugaryov\" style=\"display: inline-flex;\"><img src=\"./pictures/github.svg\" width=\"22px\" style=\"margin-right: 5px\">@artyomtugaryov</a>\n",
    "      </figcaption>\n",
    "    </figure>\n",
    "    <figure style=\"display: inline-block;\">\n",
    "      <img style=\"border-radius: 50%;\" src=\"pictures/\" width=\"150\" height=\"150\"/>\n",
    "      <figcaption style=\"text-align: center; font-weight: bold;\">Igor Salnikov</figcaption>\n",
    "      <figcaption style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/SalnikovIgor\" style=\"display: inline-flex;\"><img src=\"./pictures/github.svg\" width=\"22px\" style=\"margin-right: 5px\">@SalnikovIgor</a>\n",
    "      </figcaption>\n",
    "    </figure>\n",
    "    <figure style=\"display: inline-block;\">\n",
    "      <img style=\"border-radius: 50%;\" src=\"pictures/Savina.jpg\" width=\"150\" height=\"150\"/>\n",
    "      <figcaption style=\"text-align: center; font-weight: bold;\">Tatiana Savina</figcaption>\n",
    "      <figcaption style=\"text-align: center\">\n",
    "        <a href=\"https://github.com/tsavina\" style=\"display: inline-flex;\"><img src=\"./pictures/github.svg\" width=\"22px\" style=\"margin-right: 5px\">@tsavina</a>\n",
    "      </figcaption>\n",
    "    </figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### In This Workshop\n",
    "\n",
    "Welcome to the Deep Learning workshop, where you will find out how to start working with pre-trained neural networks and create a transformer-based zero-shot text classifier applying model optimization techniques. For that, we will be using OpenVINO™ framework and its graphical interface Deep Learning Workbench. \n",
    "\n",
    "During this workshop, you will:\n",
    "\n",
    "1. Learn the basics of neural model analysis and optimization:\n",
    "    - what a model is and how it works\n",
    "    - how to measure its performance and analyze the quality\n",
    "    - how to tune the model for enhanced performance\n",
    "2. Write your own AI application that  ...\n",
    "\n",
    "###  NLP and Deep Learning\n",
    "\n",
    "Natural Language Processing is a branch of technology devoted to the nuances of how AI understands human language. NLP technologies are making a significant breakthrough when paired with AI and Deep Learning, achieving state-of-the-art results in practically every NLP-related task.\n",
    "\n",
    "NLP is growing even more popular with ready-to-use pre-trained models and no-code technologies accessible to everyone. Businesses use NLP to improve the operations and make better judgments, in particular:  \n",
    "\n",
    "- better understand their clients and develop more effective tactics\n",
    "- regularly conduct sentiment analysis to gain a better understanding of the business, assess the response of customers to digital marketing effort\n",
    "- extract the most crucial information from a text and summarize it to speed up the process of sifting through massive volumes of data in news articles, legal documents, and scientific papers\n",
    "- aid in automatic translation, copywriting, grammar check and many other tasks. \n",
    "\n",
    "Through Deep Learning we can train models to perform tokenization and experiment with neural models to identify and understand certain rules and patterns that natural languages follow. One of the fundamental tasks in NLP is text classification - the task of assigning a label or class to a given text. Classification models are being successfully applied to solve acute challenging problems such as topic labeling, spam detection, intent detection, and especially sentiment analysis. The neural networks are implemented in sentiment analysis to compute the belongingness of labels. Sentiment analysis is used to mine subjective text, opinions and sentiments to understand feelings, however, one of the big challenges of sentiment analysis is a lack of labelled data. This is where Deep Learning models play a pivotal role, further enriching the applications of NLP.\n",
    "\n",
    "###  NLP Optimization\n",
    "\n",
    "While dealing with enormous amount of text data, model’s performance and accuracy become a challenge. The use of transformer models in production requires significant computational resources, in the DL Workbench you can accelerate neural NLP models, reducing their size and inference time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OpenVINO™ Toolkit <a name=\"OV-overview\"></a>\n",
    "\n",
    "1. [SMTH about OV](#customers) \n",
    "2. [Introduction to the Openvino toolkit](#OV-intro) \n",
    "3. [OpenVINO capabilities](#OV-capabilities)\n",
    "4. [OpenVINO components](#OV-components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 How OpenVINO advances AI technologies <a name=\"customers\"></a>\n",
    "\n",
    "The Open Visual Inference & Neural Network Optimization (OpenVINO™) toolkit is a comprehensive toolkit for optimizing pre-trained Deep Learning models of various use cases to achieve high performance and prepare them for deployment on Intel® platforms. Based on latest generations of artificial neural networks, including convolutional neural networks (CNNs), recurrent and attention-based networks, the toolkit extends computer vision and non-vision workloads across Intel® hardware, maximizing performance. It accelerates applications with high-performance, AI and deep learning inference deployed from edge to cloud.\n",
    "\n",
    "![](nlp_img/case_studies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Introduction to the OpenVINO™ toolkit <a name=\"OV-intro\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](nlp_img/ov_motivation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/about_vino.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 OpenVINO™ Capabilities <a name=\"OV-capabilities\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](nlp_img/ov_tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 OpenVINO™ Toolkit Components <a name=\"OV-components\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](nlp_img/additional_tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deep Learning Workbench: OpenVINO™ Quickstart <a name=\"DL-WB-overview\"></a>\n",
    "\n",
    "1. [DL Workbench Capabilities](#DL-WB-capabilities)\n",
    "2. [DL Workbench Workflow](#DL-WB-workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Workbench (DL Workbench) is the official OpenVINO™ graphical interface designed to make the production of pre-trained deep learning models significantly easier.\n",
    "With DL Workbench you can start working with your deep learning model right from your browser: import a model, analyze its performance and accuracy, visualize the outputs, optimize and prepare the model for deployment in a matter of minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 DL Workbench Capabilities <a name=\"DL-WB-capabilities\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cv/pictures/DL-WB-flow.png\" width=\"1400\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 DL Workbench Workflow <a name=\"DL-WB-workflow\"></a>\n",
    "\n",
    "1. [Open DL Workbench](#open-wb)\n",
    "2. [Import the Model](#import-model)\n",
    "3. [Import the Dataset](#import-dataset) \n",
    "4. [Benchmark the Model](#model-inference)\n",
    "5. [Analyze the Model](#analyze-model) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display button for opening DL Workbench\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<button class=\"wb-button\" onclick=\"window.open(location.origin, '_blank');\">Open DL Workbench</button><style>.wb-button { display: flex; width: fit-content; margin: 20px auto; align-items: center; height: 50px; font-size: 18px; font-weight: 400; font-family: inherit; line-height: 20px; background-color: #003C71; border: 1px solid #003C71; color: #ffffff; cursor: pointer; border-radius: 4px; padding: 0 30px; box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.15);}</style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open DL Workbench <a name=\"open-wb\"></a>\n",
    "\n",
    "To start working with DL Workbench, click **Create Project** button to open the Create Project page.\n",
    "\n",
    "![](pictures/start_page_dl_wb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Model <a name=\"import-model\"></a>\n",
    "\n",
    "Our first step is to import the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with OpenVINO tools, you need to obtain a model in Intermediate Representation (IR) format. \n",
    "IR is the OpenVINO format of pre-trained model representation with two files:\n",
    "\n",
    "- XML file describing the network topology\n",
    "- BIN file containing weights and biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset <a name=\"import-dataset\"></a>\n",
    "\n",
    "Next, you will need to obtain the data to work with the model. The data can be in different formats, depending on the task for which the model has been trained. Learn more about these formats in the [documentation](https://docs.openvinotoolkit.org/latest/workbench_docs_Workbench_DG_Dataset_Types.html). \n",
    "\n",
    "In our case, we will take a set of images and use them as the validation dataset:\n",
    "\n",
    " Use the following **link to download the dataset**: [Download Dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark the Model <a name=\"model-inference\"></a>\n",
    "\n",
    "Now that we have imported our model, we want to check how fast it works. For that, let's create our first project. Select the model and the dataset by clicking on them. You can also choose a hardware accelerator on which the model will be executed. We will analyze how our model works on CPU since we have this device available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Model <a name=\"analyze-model\"></a>\n",
    "\n",
    "When the inference stage is finished, we can see the result of running our model on the CPU. Latency is the time required to process one image. The lower the value, the better. Throughput is the number of images (frames) processed per second. Higher throughput value means better performance. Now let's check how the model works and try to make it even faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s briefly recap what you have learned at this stage:\n",
    "\n",
    "1. What a model is and how it works\n",
    "2. How to measure its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Learn OpenVINO™ API <a name=\"OV-API\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Let's learn how to infer a model of text classification use case with OpenVINO™ Python interface and build our application. Text classification is a task of predicting the class of the given text..\n",
    "\n",
    "We will go through the following steps:\n",
    "\n",
    "1. [Obtain Required Modules](#1.-Obtain-Required-Modules) \n",
    "2. [_Optional_. Download and convert a pretrained model from the Open Model Zoo](#2.-Optional.-Download-and-Convert-a-Pretrained-Model-from-the-Open-Model-Zoo)\n",
    "3. [Configure inference: path to a model and other data](#3.-Configure-an-Inference)\n",
    "4. [Initialize the OpenVINO™ runtime](#4.-Initialize-the-OpenVINO™-Runtime)\n",
    "5. [Read the model](#5.-Read-the-Model)\n",
    "6. [Make the model executable](#6.-Make-the-Model-Executable)\n",
    "7. [Prepare an image for model inference](#7.-Prepare-an-Image-for-Model-Inference)\n",
    "8. [Infer the model](#8.-Infer-the-Model)\n",
    "9. [Display results](#9.-Display-Results)\n",
    "10. [_Optional_. Compare OpenVINO and PyTorch model](#10.-Optional.-Compare-OpenVINO-and-PyTorch-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtain Required Modules\n",
    "Install required modules on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.5 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/numpy-1.19.5-py3.8-linux-x86_64.egg (from -r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: matplotlib==3.3.4 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (3.3.4)\n",
      "Requirement already satisfied: virtualenv==20.0.30 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (20.0.30)\n",
      "Requirement already satisfied: torch==1.10.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.10.1)\n",
      "Collecting onnx==1.10.2\n",
      "  Using cached onnx-1.10.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.7 MB)\n",
      "Requirement already satisfied: transformers==4.12.2 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/transformers-4.12.2-py3.8.egg (from -r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: sentencepiece==0.1.96 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/sentencepiece-0.1.96-py3.8-linux-x86_64.egg (from -r requirements.txt (line 9)) (0.1.96)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/kiwisolver-1.3.2-py3.8-linux-x86_64.egg (from matplotlib==3.3.4->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/python_dateutil-2.8.2-py3.8.egg (from matplotlib==3.3.4->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/cycler-0.10.0-py3.8.egg (from matplotlib==3.3.4->-r requirements.txt (line 2)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/pyparsing-3.0.0rc2-py3.8.egg (from matplotlib==3.3.4->-r requirements.txt (line 2)) (3.0.0rc2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/Pillow-8.3.2-py3.8-linux-x86_64.egg (from matplotlib==3.3.4->-r requirements.txt (line 2)) (8.3.2)\n",
      "Requirement already satisfied: six<2,>=1.9.0 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from virtualenv==20.0.30->-r requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: appdirs<2,>=1.4.3 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from virtualenv==20.0.30->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: distlib<1,>=0.3.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from virtualenv==20.0.30->-r requirements.txt (line 3)) (0.3.2)\n",
      "Requirement already satisfied: filelock<4,>=3.0.0 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from virtualenv==20.0.30->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from torch==1.10.1->-r requirements.txt (line 5)) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from onnx==1.10.2->-r requirements.txt (line 6)) (3.18.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/huggingface_hub-0.1.0-py3.8.egg (from transformers==4.12.2->-r requirements.txt (line 8)) (0.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from transformers==4.12.2->-r requirements.txt (line 8)) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from transformers==4.12.2->-r requirements.txt (line 8)) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/regex-2021.10.8-py3.8-linux-x86_64.egg (from transformers==4.12.2->-r requirements.txt (line 8)) (2021.10.8)\n",
      "Requirement already satisfied: requests in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from transformers==4.12.2->-r requirements.txt (line 8)) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/sacremoses-0.0.46-py3.8.egg (from transformers==4.12.2->-r requirements.txt (line 8)) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/tokenizers-0.10.3-py3.8-linux-x86_64.egg (from transformers==4.12.2->-r requirements.txt (line 8)) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/tqdm-4.62.3-py3.8.egg (from transformers==4.12.2->-r requirements.txt (line 8)) (4.62.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from requests->transformers==4.12.2->-r requirements.txt (line 8)) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from requests->transformers==4.12.2->-r requirements.txt (line 8)) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from requests->transformers==4.12.2->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from requests->transformers==4.12.2->-r requirements.txt (line 8)) (2021.10.8)\n",
      "Requirement already satisfied: click in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages (from sacremoses->transformers==4.12.2->-r requirements.txt (line 8)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/artur_paniukov/python/fork/workbench/.venv/lib/python3.8/site-packages/joblib-1.1.0-py3.8.egg (from sacremoses->transformers==4.12.2->-r requirements.txt (line 8)) (1.1.0)\n",
      "Installing collected packages: onnx\n",
      "  Attempting uninstall: onnx\n",
      "    Found existing installation: onnx 1.10.1\n",
      "    Uninstalling onnx-1.10.1:\n",
      "      Successfully uninstalled onnx-1.10.1\n",
      "Successfully installed onnx-1.10.2\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Python* modules that you will use in the sample code:\n",
    "- [os](https://docs.python.org/3/library/os.html#module-os) is a standard Python module used for filename parsing.\n",
    "- [time](https://docs.python.org/3/library/time.html#module-time) is a standard Python module used to measure execution time.\n",
    "- [NumPy](http://www.numpy.org/) is an array manipulation module.\n",
    "- [Deep Learning Inference Engine](https://docs.openvino.ai/latest/openvino_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html) is an OpenVINO™ Python API module used for inference.\n",
    "- [Transformers](https://huggingface.co/docs/transformers/index) if a library for working with NLP models.\n",
    "\n",
    "Run the cell below to import the modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "\n",
    "from openvino.runtime import Core\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, PretrainedConfig\n",
    "from transformers.convert_graph_to_onnx import convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. _Optional_. Download and Convert a Pretrained Model from the HuggingFace Model Hub\n",
    "\n",
    "> **NOTE**: If you already imported a model in the DL Workbench, skip this step and proceed to [configuring inference](#3.-Configure-an-Inference).\n",
    "\n",
    "OpenVINO™ toolkit includes the [Model Optimizer](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) used to convert and optimize trained models into Intermediate Representation (IR) model files, and the [Inference Engine](https://docs.openvino.ai/latest/openvino_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html), which uses the IR model files to run an inference on hardware devices. The IR model files are created from models trained in popular frameworks, like Caffe\\*, TensorFlow\\*, and others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before downloading a model, you need to configure a Python* environment to convert model from onnx framework. To do this, create a new virtual environment and install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "wheel_path = Path.cwd().parent.parent / \"wheels\"\n",
    "python_version = f\"{sys.version_info.major}{sys.version_info.minor}\"\n",
    "\n",
    "os.environ[\"OPENVINO_WHEEL\"] = next(str(path.absolute()) for path in wheel_path.iterdir() if python_version in str(path))\n",
    "os.environ[\"OPENVINO_DEV_WHEEL\"] = next(str(path.absolute()) for path in wheel_path.iterdir() if \"dev\" in str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created virtual environment CPython3.8.10.final.0-64 in 137ms\n",
      "  creator CPython3Posix(dest=/tmp/virtualenvs/onnx, clear=False, global=False)\n",
      "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/artur_paniukov/.local/share/virtualenv)\n",
      "    added seed packages: Pillow==9.0.0, PyRx==0.3.0, PyWavelets==1.2.0, PyYAML==6.0, Shapely==1.8.0, addict==2.4.0, certifi==2021.10.8, charset_normalizer==2.0.10, click==8.0.3, defusedxml==0.7.1, fast_ctc_decode==0.3.0, fastjsonschema==2.15.3, filelock==3.4.2, huggingface_hub==0.4.0, idna==3.3, imagecodecs==2020.5.30, imageio==2.13.5, joblib==1.1.0, jstyleson==0.0.2, lmdb==1.3.0, networkx==2.6.3, nibabel==3.2.1, nltk==3.6.7, numpy==1.19.5, onnx==1.10.2, opencv_python==4.5.5.62, openvino==2022.1.0.dev20220110, openvino_dev==2022.1.0.dev20220110, packaging==21.3, pandas==1.1.5, parasail==1.2.4, pip==20.2.1, pip==21.3.1, progress==1.6, protobuf==3.19.3, py_cpuinfo==8.0.0, pyclipper==1.3.0.post2, pydicom==2.2.2, pyparsing==3.0.6, python_dateutil==2.8.2, pytz==2021.3, rawpy==0.17.0, regex==2021.11.10, requests==2.27.1, sacremoses==0.0.47, scikit_image==0.19.1, scikit_learn==0.24.2, scipy==1.5.4, sentencepiece==0.1.96, setuptools==49.2.1, setuptools==59.4.0, setuptools==59.6.0, six==1.16.0, texttable==1.6.4, threadpoolctl==3.0.0, tifffile==2021.11.2, tokenizers==0.10.3, tqdm==4.62.3, transformers==4.15.0, typing_extensions==4.0.1, urllib3==1.26.8, wheel==0.34.2, wheel==0.36.2\n",
      "  activators BashActivator,CShellActivator,FishActivator,PowerShellActivator,PythonActivator,XonshActivator\n",
      "Requirement already satisfied: pip in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (21.3.1)\n",
      "Processing /home/artur_paniukov/python/fork/workbench/wheels/openvino-2022.1.0.dev20220110-6008-cp38-cp38-manylinux_2_27_x86_64.whl\n",
      "Requirement already satisfied: numpy<1.20,>=1.16.6 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino==2022.1.0.dev20220110) (1.19.5)\n",
      "openvino is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Processing /home/artur_paniukov/python/fork/workbench/wheels/openvino_dev-2022.1.0.dev20220110-6008-py3-none-any.whl\n",
      "Requirement already satisfied: shapely>=1.7.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.8.0)\n",
      "Requirement already satisfied: fast-ctc-decode>=0.2.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.3.0)\n",
      "Requirement already satisfied: numpy<1.20,>=1.16.6 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.19.5)\n",
      "Requirement already satisfied: pyclipper>=1.2.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.3.0.post2)\n",
      "Requirement already satisfied: progress>=1.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.6)\n",
      "Requirement already satisfied: jstyleson~=0.0.2 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.0.2)\n",
      "Requirement already satisfied: rawpy>=0.16.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.17.0)\n",
      "Requirement already satisfied: addict>=2.4.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2.4.0)\n",
      "Requirement already satisfied: pillow>=8.1.2 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (4.15.0)\n",
      "Requirement already satisfied: tokenizers>=0.10.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.10.3)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (6.0)\n",
      "Requirement already satisfied: nibabel>=3.2.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (3.2.1)\n",
      "Requirement already satisfied: parasail>=1.2.4 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.2.4)\n",
      "Requirement already satisfied: nltk>=3.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (3.6.7)\n",
      "Requirement already satisfied: sentencepiece>=0.1.95 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.1.96)\n",
      "Requirement already satisfied: imagecodecs~=2020.5.30 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2020.5.30)\n",
      "Requirement already satisfied: opencv-python==4.5.* in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (4.5.5.62)\n",
      "Requirement already satisfied: lmdb>=1.2.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn~=0.24.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.24.2)\n",
      "Requirement already satisfied: requests>=2.25.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2.27.1)\n",
      "Requirement already satisfied: pydicom>=2.1.2 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2.2.2)\n",
      "Requirement already satisfied: scipy~=1.5.4 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.5.4)\n",
      "Requirement already satisfied: pyrx==0.3.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.3.0)\n",
      "Requirement already satisfied: py-cpuinfo>=7.0.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (8.0.0)\n",
      "Requirement already satisfied: pandas~=1.1.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.1.5)\n",
      "Requirement already satisfied: scikit-image>=0.17.2 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.54.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (4.62.3)\n",
      "Requirement already satisfied: openvino==2022.1.0.dev20220110 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2022.1.0.dev20220110)\n",
      "Requirement already satisfied: networkx~=2.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2.6.3)\n",
      "Requirement already satisfied: texttable~=1.6.3 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.6.4)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (0.7.1)\n",
      "Requirement already satisfied: onnx>=1.8.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (1.10.2)\n",
      "Requirement already satisfied: fastjsonschema~=2.15.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from openvino-dev==2022.1.0.dev20220110) (2.15.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from nibabel>=3.2.1->openvino-dev==2022.1.0.dev20220110) (21.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from nltk>=3.5->openvino-dev==2022.1.0.dev20220110) (2021.11.10)\n",
      "Requirement already satisfied: click in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from nltk>=3.5->openvino-dev==2022.1.0.dev20220110) (8.0.3)\n",
      "Requirement already satisfied: joblib in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from nltk>=3.5->openvino-dev==2022.1.0.dev20220110) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from onnx>=1.8.1->openvino-dev==2022.1.0.dev20220110) (4.0.1)\n",
      "Requirement already satisfied: protobuf in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from onnx>=1.8.1->openvino-dev==2022.1.0.dev20220110) (3.19.3)\n",
      "Requirement already satisfied: six in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from onnx>=1.8.1->openvino-dev==2022.1.0.dev20220110) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from pandas~=1.1.5->openvino-dev==2022.1.0.dev20220110) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from pandas~=1.1.5->openvino-dev==2022.1.0.dev20220110) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from requests>=2.25.1->openvino-dev==2022.1.0.dev20220110) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from requests>=2.25.1->openvino-dev==2022.1.0.dev20220110) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from requests>=2.25.1->openvino-dev==2022.1.0.dev20220110) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from requests>=2.25.1->openvino-dev==2022.1.0.dev20220110) (2.0.10)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from scikit-image>=0.17.2->openvino-dev==2022.1.0.dev20220110) (2.13.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from scikit-image>=0.17.2->openvino-dev==2022.1.0.dev20220110) (2021.11.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from scikit-image>=0.17.2->openvino-dev==2022.1.0.dev20220110) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from scikit-learn~=0.24.1->openvino-dev==2022.1.0.dev20220110) (3.0.0)\n",
      "Requirement already satisfied: filelock in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from transformers>=4.5->openvino-dev==2022.1.0.dev20220110) (3.4.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from transformers>=4.5->openvino-dev==2022.1.0.dev20220110) (0.4.0)\n",
      "Requirement already satisfied: sacremoses in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from transformers>=4.5->openvino-dev==2022.1.0.dev20220110) (0.0.47)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /tmp/virtualenvs/onnx/lib/python3.8/site-packages (from packaging>=14.3->nibabel>=3.2.1->openvino-dev==2022.1.0.dev20220110) (3.0.6)\n",
      "openvino-dev is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "python3 -m virtualenv /tmp/virtualenvs/onnx\n",
    "source /tmp/virtualenvs/onnx/bin/activate\n",
    "\n",
    "python -m pip install --upgrade pip\n",
    "python -m pip install --upgrade ${OPENVINO_WHEEL}\n",
    "python -m pip install --upgrade ${OPENVINO_DEV_WHEEL}[ONNX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set a model checkpoint form the HF Model Hub - the [`distilbert-base-uncased-finetuned-sst-2-english`](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"SkolkovoInstitute/russian_toxicity_classifier\"\n",
    "model_name = model_checkpoint.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 Convert to Pytorch model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX opset version set to: 12\n",
      "Loading pipeline (model: SkolkovoInstitute/russian_toxicity_classifier, tokenizer: SkolkovoInstitute/russian_toxicity_classifier)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51991941a9724f9baf32990e1942c02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c675f9a8c4214869b0d9b94632d2294b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/712M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffe5835205044a3812bed943d3a87f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98fa236329a48858a0f416c86437e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045262834e69429aa7aee8f5bc94a3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder onnx_model\n",
      "Using framework PyTorch: 1.7.1+cpu\n",
      "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
      "Found output output_0 with shape: {0: 'batch'}\n",
      "Ensuring inputs are in correct order\n",
      "position_ids is not present in the generated input list.\n",
      "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artur_paniukov/python/openvino_notebooks/openvino_notebooks/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:201: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  position_ids = self.position_ids[:, past_key_values_length : seq_length + past_key_values_length]\n",
      "/home/artur_paniukov/python/openvino_notebooks/openvino_notebooks/lib/python3.8/site-packages/transformers/modeling_utils.py:2158: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert all(\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = Path(f\"onnx_model/{model_name}.onnx\")\n",
    "if onnx_model_path.parent.exists():\n",
    "    rmtree(onnx_model_path.parent)\n",
    "\n",
    "convert(\n",
    "    framework=\"pt\", \n",
    "    model=model_checkpoint, \n",
    "    output=onnx_model_path, \n",
    "    opset=12,  # check other opsets or try one more time if conversion fails\n",
    "    pipeline_name=\"sentiment-analysis\",  # default pipeline name for text classification and textual entaimnet models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Convert ONNX model to OpenVINO IR\n",
    "\n",
    "To convert the model to IR we need to set the shapes of the input tensors, that contains 2 dimentions - _batch size_ and _sequence length_. The names of input tensors are stored in the model `tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inputs: input_ids,token_type_ids,attention_mask\n",
      "Input shapes [1,128],[1,128],[1,128]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 128\n",
    "\n",
    "assert sequence_length <= tokenizer.model_max_length\n",
    "\n",
    "inputs = \",\".join(tokenizer.model_input_names)\n",
    "input_shapes = \",\".join(f\"[{batch_size},{sequence_length}]\" for _ in range(len(tokenizer.model_input_names)))\n",
    "\n",
    "print(\n",
    "    f\"Model inputs: {inputs}\\n\"\n",
    "    f\"Input shapes {input_shapes}\"\n",
    ")\n",
    "\n",
    "openvino_model_dir = Path(\"ir_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \t/home/artur_paniukov/python/fork/workbench/tutorials/opentalks/onnx_model/russian_toxicity_classifier.onnx\n",
      "\t- Path for generated IR: \t/home/artur_paniukov/python/fork/workbench/tutorials/opentalks/ir_model\n",
      "\t- IR output name: \trussian_toxicity_classifier\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tinput_ids,token_type_ids,attention_mask\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \t[1,128],[1,128],[1,128]\n",
      "\t- Source layout: \tNot specified\n",
      "\t- Target layout: \tNot specified\n",
      "\t- Layout: \tNot specified\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tNone\n",
      "\t- Reverse input channels: \tFalse\n",
      "\t- Use legacy API for model processing: \tFalse\n",
      "\t- Use the transformations config file: \tNone\n",
      "ONNX specific parameters:\n",
      "\t- OpenVINO runtime found in: \t/home/artur_paniukov/intel/openvino_2022/python/python3.8/openvino\n",
      "OpenVINO runtime version: \t2022.1.2022.1.0-6008-8fe5484645a\n",
      "Model Optimizer version: \t2022.1.0-6008-8fe5484645a\n",
      "[ WARNING ] Model Optimizer and OpenVINO runtime versions do no match.\n",
      "[ WARNING ] Consider building the OpenVINO Python API from sources or reinstall OpenVINO (TM) toolkit using \"pip install openvino==2022.1\"\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/artur_paniukov/python/fork/workbench/tutorials/opentalks/ir_model/russian_toxicity_classifier.xml\n",
      "[ SUCCESS ] BIN file: /home/artur_paniukov/python/fork/workbench/tutorials/opentalks/ir_model/russian_toxicity_classifier.bin\n",
      "[ SUCCESS ] Total execution time: 38.13 seconds. \n",
      "[ SUCCESS ] Memory consumed: 2166 MB. \n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$onnx_model_path\" \"$inputs\" \"$input_shapes\" \"$openvino_model_dir\"\n",
    "source /tmp/virtualenvs/onnx/bin/activate\n",
    "\n",
    "mo --input_model \"$1\" --input \"$2\" --input_shape \"$3\" --output_dir \"$4\" --data_type \"FP32\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Configure an Inference\n",
    "\n",
    "Once you have the OpenVINO™ IR of your model, you can start experimenting with it by inferring it and inspecting its output. \n",
    "\n",
    "> **NOTE**: If you have the model imported in DL Workbench, copy the paths to the `.xml` and `.bin` files from the DL Workbench UI and paste them below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "\n",
    "Parameter| Explanation\n",
    "---|---\n",
    "**model_xml**| Path to the `.xml` file of OpenVINO™ IR of your model\n",
    "**model_bin**| Path to the `.bin` file of OpenVINO™ IR of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model IR files\n",
    "model_xml = openvino_model_dir / f\"{model_checkpoint}.xml\"\n",
    "model_bin = openvino_model_dir / f\"{model_checkpoint}.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you define the path to the model, go to the [Initialize the OpenVINO™ Runtime](#Initialize-the-OpenVINO™-Runtime) step and execute all cells one by one to reach the [Show Predictions](#Show-Predictions) step. Then you can return and experiment with optional parameters in the section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional Parameters\n",
    "\n",
    "Experiment with optional parameters after you go the full workflow of the tutorial.\n",
    "\n",
    "Parameter| Explanation\n",
    "---|---\n",
    "**input_image_path**| Path to an input image. Use the `dog.jpg` image placed in the directory of the notebook or, if you have imported a dataset in the DL Workbench, copy the path to an image in the dataset.\n",
    "**device**| Specify the [target device](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Select_Environment.html) to infer on: CPU, GPU, or MYRIAD. Note that the device must be present. For this tutorial, use `CPU` which is known to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration parameters settings:\n",
      "\tmodel_xml=ir_model/SkolkovoInstitute/russian_toxicity_classifier.xml \n",
      "\tmodel_bin=ir_model/SkolkovoInstitute/russian_toxicity_classifier.bin \n",
      "\tdevice=CPU\n"
     ]
    }
   ],
   "source": [
    "# Device to use\n",
    "device = \"CPU\"\n",
    "\n",
    "print(\n",
    "    \"Configuration parameters settings:\"\n",
    "    f\"\\n\\tmodel_xml={model_xml}\",\n",
    "    f\"\\n\\tmodel_bin={model_bin}\",\n",
    "    f\"\\n\\tdevice={device}\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initialize the OpenVINO™ Runtime\n",
    "\n",
    "Once you define the parameters, let's initiate the `Core` object that accesses OpenVINO™ runtime capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Inference Engine instance\n",
    "core = Core()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Read the Model\n",
    "\n",
    "Put the IR of your model in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Model file ir_model/SkolkovoInstitute/russian_toxicity_classifier.xml cannot be opened!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8132ded57b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read the network from IR files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_xml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Set input tensor names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Model file ir_model/SkolkovoInstitute/russian_toxicity_classifier.xml cannot be opened!"
     ]
    }
   ],
   "source": [
    "# Read the network from IR files\n",
    "model = core.read_model(model=model_xml, weights=model_bin)\n",
    "\n",
    "# Set input tensor names\n",
    "for inp, name in zip(model.inputs, tokenizer.model_input_names):\n",
    "    inp.get_tensor().set_names({name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make the Model Executable\n",
    "\n",
    "Reading a network is not enough to start a model inference. The model must be loaded to a particular abstraction representing a particular accelerator. In OpenVINO™, this abstraction is called *plugin*. A network loaded to a plugin becomes executable and will be inferred in one of the next steps.\n",
    "\n",
    "After loading, we keep necessary model information - `output_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = core.compile_model(model=model, device_name=device)\n",
    "\n",
    "output_name = model.output().any_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Prepare a Text for Model Inference\n",
    "\n",
    "The model cannot work with the text directly. Instead, the text is first split into tokens and then replaces each token with the corresponding index. A token can be a word, part of a word, a symbol, or a couple of symbols. The map between tokens and indices is stored by the tokenizer.\n",
    "\n",
    "The model input that takes token indices is usually called `input_ids`. There are also might be other inputs. If the model input is static, meaning that it can take only fixed-size inputs, one could have to make an input text longer. For that, there is a special token, called _padding_, that can be added to the beginning or to the end of the sequence. To ignore these tokens during inference there is an `attention_mask` model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The movie was good.\"\n",
    "\n",
    "tokenized_text = tokenizer(\n",
    "    input_text,\n",
    "    padding=True,\n",
    "    pad_to_multiple_of=sequence_length,\n",
    "    return_tensors=\"np\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Infer the Model\n",
    "\n",
    "Now that you have the input image in the BGR format and of the right size, you can perform the inference of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the starting time\n",
    "inf_start = time.time()\n",
    "\n",
    "# Run the inference\n",
    "res = compiled_model.infer_new_request(dict(**tokenized_text))\n",
    "res = {output.any_name: output_tensor for output, output_tensor in res.items()}  \n",
    "\n",
    "# Calculate the time from the start until now\n",
    "inf_time = time.time() - inf_start\n",
    "print(f\"Inference is complete. Run time: {inf_time * 1000:.3f} ms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Display Results\n",
    "\n",
    "Now `res` contains the result of the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load index to label map from model config\n",
    "model_config = PretrainedConfig.from_pretrained(model_checkpoint)\n",
    "idx_to_label_dict = getattr(model_config, \"id2label\", {})\n",
    "\n",
    "# create function that can be applied to vectors\n",
    "# if there is no `idx_to_label` map, the function returns class index\n",
    "idx_to_label = np.vectorize(lambda x: idx_to_label_dict.get(x, x))\n",
    "\n",
    "def process_result(res):\n",
    "    result_logits = res[output_name]\n",
    "    \n",
    "    # take the position of the maximum element in the vector to get the predicted class index\n",
    "    predicted_class_idx = np.argmax(result_logits, axis=1)\n",
    "    \n",
    "    # transform class index to class label\n",
    "    return idx_to_label(predicted_class_idx)\n",
    "\n",
    "process_result(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. _Optional_. Compare OpenVINO and PyTorch model\n",
    "\n",
    "A model conversion process could fail due to many reasons. For example, the target framework did not support some operations from the source framework. But the model output might change drastically compared to the original model, even if the conversion process is finished without any errors. Since there are two conversions performed in the tutorial (from Pytorch to ONNX and from ONNX to OpenVINO) it is advised to check if the converted model predictions are close to the original model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_logits_is_close(one, other):\n",
    "    is_close = np.isclose(one, other, rtol=1e-04, atol=1e-04)\n",
    "    diff = np.abs(np.abs(one) - np.abs(other))\n",
    "    assert np.all(is_close), f\"Max diff is {np.max(diff * ~is_close)}\"\n",
    "    \n",
    "pytorch_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "tokenized_text_pt = tokenizer(\n",
    "        input_text,\n",
    "        padding=True,\n",
    "        pad_to_multiple_of=sequence_length,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "pytorch_res = pytorch_model(**tokenized_text_pt)\n",
    "\n",
    "check_logits_is_close(\n",
    "    res[output_name], \n",
    "    pytorch_res.logits.detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you can proceed to importing the model into the DL Workbench or if you have already done that, start exploring numerous features such as:\n",
    "\n",
    "* [Analyse how the model works and its quality](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Visualize_Accuracy.html)\n",
    "* [Perform a baseline inference and analyze model performance](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Run_Single_Inference.html)\n",
    "* [Boost the model by calibrating it to the INT8 precision](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Int_8_Quantization.html)\n",
    "* [Tune the performance of the model by selecting optimal inference parameters](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Run_Range_of_Inferences.html)\n",
    "* [Preparing the model for deployment](https://docs.openvino.ai/latest/workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice <a name=\"tasks\"></a>\n",
    "\n",
    "1. [Task 1: ](#task1) \n",
    "2. [Task 2: ](#task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:  <a name=\"task1\"></a>\n",
    "\n",
    "The goal of this task is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:  <a name=\"task2\"></a>\n",
    "\n",
    "Now that we have learned how to ...., let's try to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Deploy your first OpenVINO application as a telegram bot <a name=\"bot\"></a>\n",
    "\n",
    "\n",
    "When you find an optimal configuration for your model, the next step is to use this model with optimal parameters in your own application on a target device. OpenVINO™ toolkit includes all you need to run the application on the target. However, the target might have a limited drive space to store all OpenVINO™ components. OpenVINO™ Deployment Manager available inside the DL Workbench extracts the minimum set of libraries required for a target device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Next steps with OpenVINO <a name=\"next-steps\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Try Workbench right now: locally or in DevCloud\n",
    "\n",
    "![](workshops/cv/pictures/call-to-action.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. [Intel® Edge AI Certification](https://www.intel.com/content/www/us/en/developer/tools/devcloud/edge/learn/certification.html)\n",
    "\n",
    "![](pictures/edge-ai-certification.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_notebooks",
   "language": "python",
   "name": "openvino_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
